{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jellyjellyjinjin/Daycon-car-object-detection-/blob/main/yolov5_Resume_freeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny_0Oqnw_pPo",
        "outputId": "f63b72a7-9cf5-4cf7-9d92-d093d3fb488f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!unzip /content/drive/MyDrive/open.zip"
      ],
      "metadata": {
        "id": "sWM6clICFj-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FZcshI22uhGK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob as glob\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_yolo_dataset(image_paths, txt_paths, type=\"train\"):\n",
        "    for image_path, txt_path in tqdm(zip(image_paths, txt_paths if not type == \"test\" else image_paths), total=len(image_paths)):\n",
        "        source_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "        image_height, image_width, _ = source_image.shape\n",
        "\n",
        "        target_image_path = f\"/content/input/{type}/{os.path.basename(image_path)}\"\n",
        "        cv2.imwrite(target_image_path, source_image)\n",
        "\n",
        "        if type == \"test\":\n",
        "            continue\n",
        "\n",
        "        with open(txt_path, \"r\") as reader:\n",
        "            yolo_labels = []\n",
        "            for line in reader.readlines():\n",
        "                line = list(map(float, line.strip().split(\" \")))\n",
        "                class_name = int(line[0])\n",
        "                x_min, y_min = float(min(line[5], line[7])), float(min(line[6], line[8]))\n",
        "                x_max, y_max = float(max(line[1], line[3])), float(max(line[2], line[4]))\n",
        "                x, y = float(((x_min + x_max) / 2) / image_width), float(((y_min + y_max) / 2) / image_height)\n",
        "                w, h = abs(x_max - x_min) / image_width, abs(y_max - y_min) / image_height\n",
        "                yolo_labels.append(f\"{class_name} {x} {y} {w} {h}\")\n",
        "\n",
        "        target_label_txt = f\"/content/input/{type}/{os.path.basename(txt_path)}\"\n",
        "        with open(target_label_txt, \"w\") as writer:\n",
        "            for yolo_label in yolo_labels:\n",
        "                writer.write(f\"{yolo_label}\\n\")"
      ],
      "metadata": {
        "id": "J-Dj9eyAcUy8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_yolo_dataset(train_img, train_txt, \"train\")\n",
        "make_yolo_dataset(valid_img, valid_txt, \"valid\")\n",
        "make_yolo_dataset(sorted(glob.glob(\"/content/test/*\")), None, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTu6OqrDcXMZ",
        "outputId": "c40b0bbc-0b73-4d46-ead1-43f9cb1dd442"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5184/5184 [17:27<00:00,  4.95it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1297/1297 [04:23<00:00,  4.92it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3400/3400 [09:27<00:00,  5.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVuzlANQcbpx",
        "outputId": "00ed27bf-d7c5-4ccc-d6d3-a0440b6407ea"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15930, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 15930 (delta 23), reused 26 (delta 9), pack-reused 15880\u001b[K\n",
            "Receiving objects: 100% (15930/15930), 14.60 MiB | 21.88 MiB/s, done.\n",
            "Resolving deltas: 100% (10922/10922), done.\n",
            "/content/yolov5\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m610.8/610.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = True"
      ],
      "metadata": {
        "id": "aZCFZVlGcdx8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/yolov5\n",
        "\n",
        "if TRAIN:\n",
        "    !python train.py --resume"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjPhPe6uck06",
        "outputId": "8daceea1-88e4-49f0-ed59-b65e43757b72"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data/coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=True, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-211-g94e943e Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir f/content/drive/MyDrive/ATL/weight/freeze', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1    262431  models.yolo.Detect                      [34, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model summary: 445 layers, 86439871 parameters, 86439871 gradients, 205.3 GFLOPs\n",
            "\n",
            "Transferred 745/745 items from f/content/drive/MyDrive/ATL/weight/freeze/yolov5x_result/weights/last.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "freezing model.0.conv.weight\n",
            "freezing model.0.bn.weight\n",
            "freezing model.0.bn.bias\n",
            "freezing model.1.conv.weight\n",
            "freezing model.1.bn.weight\n",
            "freezing model.1.bn.bias\n",
            "freezing model.2.cv1.conv.weight\n",
            "freezing model.2.cv1.bn.weight\n",
            "freezing model.2.cv1.bn.bias\n",
            "freezing model.2.cv2.conv.weight\n",
            "freezing model.2.cv2.bn.weight\n",
            "freezing model.2.cv2.bn.bias\n",
            "freezing model.2.cv3.conv.weight\n",
            "freezing model.2.cv3.bn.weight\n",
            "freezing model.2.cv3.bn.bias\n",
            "freezing model.2.m.0.cv1.conv.weight\n",
            "freezing model.2.m.0.cv1.bn.weight\n",
            "freezing model.2.m.0.cv1.bn.bias\n",
            "freezing model.2.m.0.cv2.conv.weight\n",
            "freezing model.2.m.0.cv2.bn.weight\n",
            "freezing model.2.m.0.cv2.bn.bias\n",
            "freezing model.2.m.1.cv1.conv.weight\n",
            "freezing model.2.m.1.cv1.bn.weight\n",
            "freezing model.2.m.1.cv1.bn.bias\n",
            "freezing model.2.m.1.cv2.conv.weight\n",
            "freezing model.2.m.1.cv2.bn.weight\n",
            "freezing model.2.m.1.cv2.bn.bias\n",
            "freezing model.2.m.2.cv1.conv.weight\n",
            "freezing model.2.m.2.cv1.bn.weight\n",
            "freezing model.2.m.2.cv1.bn.bias\n",
            "freezing model.2.m.2.cv2.conv.weight\n",
            "freezing model.2.m.2.cv2.bn.weight\n",
            "freezing model.2.m.2.cv2.bn.bias\n",
            "freezing model.2.m.3.cv1.conv.weight\n",
            "freezing model.2.m.3.cv1.bn.weight\n",
            "freezing model.2.m.3.cv1.bn.bias\n",
            "freezing model.2.m.3.cv2.conv.weight\n",
            "freezing model.2.m.3.cv2.bn.weight\n",
            "freezing model.2.m.3.cv2.bn.bias\n",
            "freezing model.3.conv.weight\n",
            "freezing model.3.bn.weight\n",
            "freezing model.3.bn.bias\n",
            "freezing model.4.cv1.conv.weight\n",
            "freezing model.4.cv1.bn.weight\n",
            "freezing model.4.cv1.bn.bias\n",
            "freezing model.4.cv2.conv.weight\n",
            "freezing model.4.cv2.bn.weight\n",
            "freezing model.4.cv2.bn.bias\n",
            "freezing model.4.cv3.conv.weight\n",
            "freezing model.4.cv3.bn.weight\n",
            "freezing model.4.cv3.bn.bias\n",
            "freezing model.4.m.0.cv1.conv.weight\n",
            "freezing model.4.m.0.cv1.bn.weight\n",
            "freezing model.4.m.0.cv1.bn.bias\n",
            "freezing model.4.m.0.cv2.conv.weight\n",
            "freezing model.4.m.0.cv2.bn.weight\n",
            "freezing model.4.m.0.cv2.bn.bias\n",
            "freezing model.4.m.1.cv1.conv.weight\n",
            "freezing model.4.m.1.cv1.bn.weight\n",
            "freezing model.4.m.1.cv1.bn.bias\n",
            "freezing model.4.m.1.cv2.conv.weight\n",
            "freezing model.4.m.1.cv2.bn.weight\n",
            "freezing model.4.m.1.cv2.bn.bias\n",
            "freezing model.4.m.2.cv1.conv.weight\n",
            "freezing model.4.m.2.cv1.bn.weight\n",
            "freezing model.4.m.2.cv1.bn.bias\n",
            "freezing model.4.m.2.cv2.conv.weight\n",
            "freezing model.4.m.2.cv2.bn.weight\n",
            "freezing model.4.m.2.cv2.bn.bias\n",
            "freezing model.4.m.3.cv1.conv.weight\n",
            "freezing model.4.m.3.cv1.bn.weight\n",
            "freezing model.4.m.3.cv1.bn.bias\n",
            "freezing model.4.m.3.cv2.conv.weight\n",
            "freezing model.4.m.3.cv2.bn.weight\n",
            "freezing model.4.m.3.cv2.bn.bias\n",
            "freezing model.4.m.4.cv1.conv.weight\n",
            "freezing model.4.m.4.cv1.bn.weight\n",
            "freezing model.4.m.4.cv1.bn.bias\n",
            "freezing model.4.m.4.cv2.conv.weight\n",
            "freezing model.4.m.4.cv2.bn.weight\n",
            "freezing model.4.m.4.cv2.bn.bias\n",
            "freezing model.4.m.5.cv1.conv.weight\n",
            "freezing model.4.m.5.cv1.bn.weight\n",
            "freezing model.4.m.5.cv1.bn.bias\n",
            "freezing model.4.m.5.cv2.conv.weight\n",
            "freezing model.4.m.5.cv2.bn.weight\n",
            "freezing model.4.m.5.cv2.bn.bias\n",
            "freezing model.4.m.6.cv1.conv.weight\n",
            "freezing model.4.m.6.cv1.bn.weight\n",
            "freezing model.4.m.6.cv1.bn.bias\n",
            "freezing model.4.m.6.cv2.conv.weight\n",
            "freezing model.4.m.6.cv2.bn.weight\n",
            "freezing model.4.m.6.cv2.bn.bias\n",
            "freezing model.4.m.7.cv1.conv.weight\n",
            "freezing model.4.m.7.cv1.bn.weight\n",
            "freezing model.4.m.7.cv1.bn.bias\n",
            "freezing model.4.m.7.cv2.conv.weight\n",
            "freezing model.4.m.7.cv2.bn.weight\n",
            "freezing model.4.m.7.cv2.bn.bias\n",
            "freezing model.5.conv.weight\n",
            "freezing model.5.bn.weight\n",
            "freezing model.5.bn.bias\n",
            "freezing model.6.cv1.conv.weight\n",
            "freezing model.6.cv1.bn.weight\n",
            "freezing model.6.cv1.bn.bias\n",
            "freezing model.6.cv2.conv.weight\n",
            "freezing model.6.cv2.bn.weight\n",
            "freezing model.6.cv2.bn.bias\n",
            "freezing model.6.cv3.conv.weight\n",
            "freezing model.6.cv3.bn.weight\n",
            "freezing model.6.cv3.bn.bias\n",
            "freezing model.6.m.0.cv1.conv.weight\n",
            "freezing model.6.m.0.cv1.bn.weight\n",
            "freezing model.6.m.0.cv1.bn.bias\n",
            "freezing model.6.m.0.cv2.conv.weight\n",
            "freezing model.6.m.0.cv2.bn.weight\n",
            "freezing model.6.m.0.cv2.bn.bias\n",
            "freezing model.6.m.1.cv1.conv.weight\n",
            "freezing model.6.m.1.cv1.bn.weight\n",
            "freezing model.6.m.1.cv1.bn.bias\n",
            "freezing model.6.m.1.cv2.conv.weight\n",
            "freezing model.6.m.1.cv2.bn.weight\n",
            "freezing model.6.m.1.cv2.bn.bias\n",
            "freezing model.6.m.2.cv1.conv.weight\n",
            "freezing model.6.m.2.cv1.bn.weight\n",
            "freezing model.6.m.2.cv1.bn.bias\n",
            "freezing model.6.m.2.cv2.conv.weight\n",
            "freezing model.6.m.2.cv2.bn.weight\n",
            "freezing model.6.m.2.cv2.bn.bias\n",
            "freezing model.6.m.3.cv1.conv.weight\n",
            "freezing model.6.m.3.cv1.bn.weight\n",
            "freezing model.6.m.3.cv1.bn.bias\n",
            "freezing model.6.m.3.cv2.conv.weight\n",
            "freezing model.6.m.3.cv2.bn.weight\n",
            "freezing model.6.m.3.cv2.bn.bias\n",
            "freezing model.6.m.4.cv1.conv.weight\n",
            "freezing model.6.m.4.cv1.bn.weight\n",
            "freezing model.6.m.4.cv1.bn.bias\n",
            "freezing model.6.m.4.cv2.conv.weight\n",
            "freezing model.6.m.4.cv2.bn.weight\n",
            "freezing model.6.m.4.cv2.bn.bias\n",
            "freezing model.6.m.5.cv1.conv.weight\n",
            "freezing model.6.m.5.cv1.bn.weight\n",
            "freezing model.6.m.5.cv1.bn.bias\n",
            "freezing model.6.m.5.cv2.conv.weight\n",
            "freezing model.6.m.5.cv2.bn.weight\n",
            "freezing model.6.m.5.cv2.bn.bias\n",
            "freezing model.6.m.6.cv1.conv.weight\n",
            "freezing model.6.m.6.cv1.bn.weight\n",
            "freezing model.6.m.6.cv1.bn.bias\n",
            "freezing model.6.m.6.cv2.conv.weight\n",
            "freezing model.6.m.6.cv2.bn.weight\n",
            "freezing model.6.m.6.cv2.bn.bias\n",
            "freezing model.6.m.7.cv1.conv.weight\n",
            "freezing model.6.m.7.cv1.bn.weight\n",
            "freezing model.6.m.7.cv1.bn.bias\n",
            "freezing model.6.m.7.cv2.conv.weight\n",
            "freezing model.6.m.7.cv2.bn.weight\n",
            "freezing model.6.m.7.cv2.bn.bias\n",
            "freezing model.6.m.8.cv1.conv.weight\n",
            "freezing model.6.m.8.cv1.bn.weight\n",
            "freezing model.6.m.8.cv1.bn.bias\n",
            "freezing model.6.m.8.cv2.conv.weight\n",
            "freezing model.6.m.8.cv2.bn.weight\n",
            "freezing model.6.m.8.cv2.bn.bias\n",
            "freezing model.6.m.9.cv1.conv.weight\n",
            "freezing model.6.m.9.cv1.bn.weight\n",
            "freezing model.6.m.9.cv1.bn.bias\n",
            "freezing model.6.m.9.cv2.conv.weight\n",
            "freezing model.6.m.9.cv2.bn.weight\n",
            "freezing model.6.m.9.cv2.bn.bias\n",
            "freezing model.6.m.10.cv1.conv.weight\n",
            "freezing model.6.m.10.cv1.bn.weight\n",
            "freezing model.6.m.10.cv1.bn.bias\n",
            "freezing model.6.m.10.cv2.conv.weight\n",
            "freezing model.6.m.10.cv2.bn.weight\n",
            "freezing model.6.m.10.cv2.bn.bias\n",
            "freezing model.6.m.11.cv1.conv.weight\n",
            "freezing model.6.m.11.cv1.bn.weight\n",
            "freezing model.6.m.11.cv1.bn.bias\n",
            "freezing model.6.m.11.cv2.conv.weight\n",
            "freezing model.6.m.11.cv2.bn.weight\n",
            "freezing model.6.m.11.cv2.bn.bias\n",
            "freezing model.7.conv.weight\n",
            "freezing model.7.bn.weight\n",
            "freezing model.7.bn.bias\n",
            "freezing model.8.cv1.conv.weight\n",
            "freezing model.8.cv1.bn.weight\n",
            "freezing model.8.cv1.bn.bias\n",
            "freezing model.8.cv2.conv.weight\n",
            "freezing model.8.cv2.bn.weight\n",
            "freezing model.8.cv2.bn.bias\n",
            "freezing model.8.cv3.conv.weight\n",
            "freezing model.8.cv3.bn.weight\n",
            "freezing model.8.cv3.bn.bias\n",
            "freezing model.8.m.0.cv1.conv.weight\n",
            "freezing model.8.m.0.cv1.bn.weight\n",
            "freezing model.8.m.0.cv1.bn.bias\n",
            "freezing model.8.m.0.cv2.conv.weight\n",
            "freezing model.8.m.0.cv2.bn.weight\n",
            "freezing model.8.m.0.cv2.bn.bias\n",
            "freezing model.8.m.1.cv1.conv.weight\n",
            "freezing model.8.m.1.cv1.bn.weight\n",
            "freezing model.8.m.1.cv1.bn.bias\n",
            "freezing model.8.m.1.cv2.conv.weight\n",
            "freezing model.8.m.1.cv2.bn.weight\n",
            "freezing model.8.m.1.cv2.bn.bias\n",
            "freezing model.8.m.2.cv1.conv.weight\n",
            "freezing model.8.m.2.cv1.bn.weight\n",
            "freezing model.8.m.2.cv1.bn.bias\n",
            "freezing model.8.m.2.cv2.conv.weight\n",
            "freezing model.8.m.2.cv2.bn.weight\n",
            "freezing model.8.m.2.cv2.bn.bias\n",
            "freezing model.8.m.3.cv1.conv.weight\n",
            "freezing model.8.m.3.cv1.bn.weight\n",
            "freezing model.8.m.3.cv1.bn.bias\n",
            "freezing model.8.m.3.cv2.conv.weight\n",
            "freezing model.8.m.3.cv2.bn.weight\n",
            "freezing model.8.m.3.cv2.bn.bias\n",
            "freezing model.9.cv1.conv.weight\n",
            "freezing model.9.cv1.bn.weight\n",
            "freezing model.9.cv1.bn.bias\n",
            "freezing model.9.cv2.conv.weight\n",
            "freezing model.9.cv2.bn.weight\n",
            "freezing model.9.cv2.bn.bias\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
            "Resuming training from f/content/drive/MyDrive/ATL/weight/freeze/yolov5x_result/weights/last.pt from epoch 41 to 70 total epochs\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/input/train... 5184 images, 0 backgrounds, 0 corrupt: 100% 5184/5184 [00:54<00:00, 95.67it/s] \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/input/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/input/valid... 1297 images, 0 backgrounds, 0 corrupt: 100% 1297/1297 [00:12<00:00, 103.65it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/input/valid.cache\n",
            "Plotting labels to f/content/drive/MyDrive/ATL/weight/freeze/yolov5x_result/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mf/content/drive/MyDrive/ATL/weight/freeze/yolov5x_result\u001b[0m\n",
            "Starting training for 70 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/69      3.56G   0.005374   0.005003   0.003206         39        640: 100% 648/648 [03:27<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:21<00:00,  3.86it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/69      3.58G   0.005263   0.004933   0.003463         39        640: 100% 648/648 [03:26<00:00,  3.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  3.93it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/69      3.58G   0.005114   0.004889   0.002937         43        640: 100% 648/648 [03:24<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  4.06it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/69      3.58G   0.005154   0.004876   0.003177         34        640: 100% 648/648 [03:24<00:00,  3.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  4.06it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/69      3.58G   0.004943   0.004723   0.002862         38        640: 100% 648/648 [03:22<00:00,  3.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  4.06it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/69      3.58G   0.004857   0.004668   0.002892         43        640: 100% 648/648 [03:20<00:00,  3.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:19<00:00,  4.17it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/69      3.58G   0.004531   0.004425   0.002555         34        640: 100% 648/648 [03:18<00:00,  3.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:19<00:00,  4.13it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/69      3.58G   0.004517   0.004424   0.002643         32        640: 100% 648/648 [03:21<00:00,  3.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:19<00:00,  4.31it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/69      3.58G   0.004494   0.004399   0.002472         37        640: 100% 648/648 [03:16<00:00,  3.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:18<00:00,  4.34it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/69      3.58G   0.004685   0.004589   0.002766         39        640: 100% 648/648 [03:15<00:00,  3.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  3.97it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/69      3.58G    0.00449   0.004374   0.002479         39        640: 100% 648/648 [03:15<00:00,  3.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  4.02it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/69      3.58G   0.004474   0.004402   0.002225         39        640: 100% 648/648 [03:24<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  4.06it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/69      3.58G   0.004249   0.004152   0.002381         34        640: 100% 648/648 [03:22<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:19<00:00,  4.17it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/69      3.58G   0.004107   0.004124   0.002191         38        640: 100% 648/648 [03:25<00:00,  3.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  3.96it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/69      3.58G   0.004076   0.004108   0.002248         36        640: 100% 648/648 [03:27<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  4.02it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/69      3.58G   0.003999   0.003989   0.001973         33        640: 100% 648/648 [03:27<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:19<00:00,  4.14it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/69      3.58G    0.00395   0.003948   0.002125         38        640: 100% 648/648 [03:27<00:00,  3.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:19<00:00,  4.14it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/69      3.58G   0.003917   0.003929   0.002121         33        640: 100% 648/648 [03:22<00:00,  3.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  4.05it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/69      3.58G   0.003746   0.003741   0.002005         32        640: 100% 648/648 [03:23<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  4.01it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/69      3.58G   0.003575   0.003616   0.001693         39        640: 100% 648/648 [03:25<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  3.99it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/69      3.58G   0.003695   0.003788    0.00186         39        640: 100% 648/648 [03:23<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  3.99it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/69      3.58G   0.003507   0.003594   0.001665         35        640: 100% 648/648 [03:22<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  4.09it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/69      3.58G    0.00337   0.003453   0.001627         37        640: 100% 648/648 [03:24<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:19<00:00,  4.13it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/69      3.58G    0.00333   0.003436   0.001372         42        640: 100% 648/648 [03:21<00:00,  3.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:19<00:00,  4.12it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/69      3.58G   0.003233   0.003313   0.001372         44        640: 100% 648/648 [03:21<00:00,  3.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:19<00:00,  4.15it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/69      3.58G   0.003083   0.003224    0.00127         33        640: 100% 648/648 [03:22<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:19<00:00,  4.30it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/69      3.58G    0.00306   0.003217   0.001333         32        640: 100% 648/648 [03:22<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:19<00:00,  4.15it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/69      3.58G   0.002885   0.003074   0.001236         37        640: 100% 648/648 [03:25<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  3.99it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/69      3.58G   0.002799   0.002978    0.00107         35        640: 100% 648/648 [03:23<00:00,  3.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:20<00:00,  3.93it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "\n",
            "29 epochs completed in 1.821 hours.\n",
            "Optimizer stripped from f/content/drive/MyDrive/ATL/weight/freeze/yolov5x_result/weights/last.pt, 173.5MB\n",
            "Optimizer stripped from f/content/drive/MyDrive/ATL/weight/freeze/yolov5x_result/weights/best.pt, 173.5MB\n",
            "\n",
            "Validating f/content/drive/MyDrive/ATL/weight/freeze/yolov5x_result/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86395471 parameters, 0 gradients, 204.5 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 82/82 [00:21<00:00,  3.79it/s]\n",
            "                   all       1297       3346      0.999          1      0.995      0.995\n",
            "chevrolet_malibu_sedan_2012_2016       1297         89      0.999          1      0.995      0.995\n",
            "chevrolet_malibu_sedan_2017_2019       1297        103      0.999          1      0.995      0.995\n",
            "chevrolet_spark_hatchback_2016_2021       1297        125          1          1      0.995      0.995\n",
            "chevrolet_trailblazer_suv_2021_       1297        106      0.999          1      0.995      0.995\n",
            "chevrolet_trax_suv_2017_2019       1297         99      0.999          1      0.995      0.995\n",
            "genesis_g80_sedan_2016_2020       1297        100      0.999          1      0.995      0.995\n",
            "genesis_g80_sedan_2021_       1297         91      0.999          1      0.995      0.995\n",
            "genesis_gv80_suv_2020_       1297         93      0.999          1      0.995      0.995\n",
            "hyundai_avante_sedan_2011_2015       1297        100          1          1      0.995      0.995\n",
            "hyundai_avante_sedan_2020_       1297         82      0.999          1      0.995      0.995\n",
            "hyundai_grandeur_sedan_2011_2016       1297         94      0.999          1      0.995      0.995\n",
            "hyundai_grandstarex_van_2018_2020       1297        106          1          1      0.995      0.995\n",
            "hyundai_ioniq_hatchback_2016_2019       1297         99      0.999          1      0.995      0.995\n",
            "hyundai_sonata_sedan_2004_2009       1297        109          1          1      0.995      0.995\n",
            "hyundai_sonata_sedan_2010_2014       1297        101      0.999          1      0.995      0.995\n",
            "hyundai_sonata_sedan_2019_2020       1297        108          1          1      0.995      0.995\n",
            "kia_carnival_van_2015_2020       1297        101      0.999          1      0.995      0.995\n",
            "kia_carnival_van_2021_       1297        105      0.999          1      0.995      0.995\n",
            "kia_k5_sedan_2010_2015       1297         90      0.999          1      0.995      0.995\n",
            "    kia_k5_sedan_2020_       1297         93      0.999          1      0.995      0.995\n",
            "kia_k7_sedan_2016_2020       1297        112          1          1      0.995      0.995\n",
            "  kia_mohave_suv_2020_       1297         89      0.999          1      0.995      0.995\n",
            "kia_morning_hatchback_2004_2010       1297         99      0.999          1      0.995      0.995\n",
            "kia_morning_hatchback_2011_2016       1297         94      0.999          1      0.995      0.995\n",
            "kia_ray_hatchback_2012_2017       1297         92      0.999          1      0.995      0.995\n",
            "kia_sorrento_suv_2015_2019       1297         93      0.999          1      0.995      0.995\n",
            "kia_sorrento_suv_2020_       1297        105          1          1      0.995      0.995\n",
            "kia_soul_suv_2014_2018       1297         96      0.999          1      0.995      0.995\n",
            "kia_sportage_suv_2016_2020       1297         88      0.999          1      0.995      0.995\n",
            "kia_stonic_suv_2017_2019       1297         99      0.999          1      0.995      0.995\n",
            "renault_sm3_sedan_2015_2018       1297        109          1          1      0.995      0.995\n",
            " renault_xm3_suv_2020_       1297         85      0.999          1      0.995      0.995\n",
            "ssangyong_korando_suv_2019_2020       1297         87      0.999          1      0.995      0.995\n",
            "ssangyong_tivoli_suv_2016_2020       1297        104      0.999          1      0.995      0.995\n",
            "Results saved to \u001b[1mf/content/drive/MyDrive/ATL/weight/freeze/yolov5x_result\u001b[0m\n",
            "CPU times: user 1min 8s, sys: 7.16 s, total: 1min 15s\n",
            "Wall time: 1h 51min 29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp /content/yolov5/f/content/drive/MyDrive/ATL/weight/freeze/yolov5x_result/weights/best.pt /content/drive/MyDrive/ATL/weight/resumeFreeze\n",
        "%cp /content/yolov5/f/content/drive/MyDrive/ATL/weight/freeze/yolov5x_result/weights/last.pt /content/drive/MyDrive/ATL/weight/resumeFreeze"
      ],
      "metadata": {
        "id": "-KQzdVv7_scj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/ATL/weight/resumeFreeze/best.pt --img 640  --source /content/input/test --save-conf --save-txt"
      ],
      "metadata": {
        "id": "chhspqSZ_5_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('/content/sample_submission.csv', header=0)\n",
        "submit.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvsdCW3DCruW",
        "outputId": "9faa81fa-3247-4e62-d078-d91ec9a4770a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['file_name', 'class_id', 'confidence', 'point1_x', 'point1_y',\n",
              "       'point2_x', 'point2_y', 'point3_x', 'point3_y', 'point4_x', 'point4_y'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import glob\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Ub0OZ-5VDQlI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer_txt_list = glob.glob('/content/yolov5/runs/detect/exp/labels/*.txt')"
      ],
      "metadata": {
        "id": "2UArooLVCtlc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_to_labelme(line, image_width, image_height, txt_file_name):\n",
        "    file_name = txt_file_name.split(\"/\")[-1].replace(\".txt\", \".png\")\n",
        "    class_id, x, y, width, height, confidence = [float(temp) for temp in line.split()]\n",
        "\n",
        "    x_min = int((x - width / 2) * image_width)\n",
        "    x_max = int((x + width / 2) * image_width)\n",
        "    y_min = int((y - height / 2) * image_height)\n",
        "    y_max = int((y + height / 2) * image_height)\n",
        "\n",
        "    return file_name, int(class_id), confidence, x_min, y_max, x_max, y_max, x_max, y_min, x_min, y_min"
      ],
      "metadata": {
        "id": "rwarAsG_C1Q4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.DataFrame(columns=['file_name', 'class_id', 'confidence', 'point1_x', 'point1_y', 'point2_x', 'point2_y', 'point3_x', 'point3_y', 'point4_x', 'point4_y'])\n",
        "\n",
        "for txt in tqdm(infer_txt_list):\n",
        "    with open(txt, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        base_file_name = txt.split('/')[-1].split('.')[0]\n",
        "        img_height, img_width = cv2.imread('/content/yolov5/runs/detect/exp/' + base_file_name + '.png').shape[:2]\n",
        "        for line in lines:\n",
        "            file_name, class_id, confidence, point1_x, point1_y, point2_x, point2_y, point3_x, point3_y, point4_x, point4_y = yolo_to_labelme(line, img_width, img_height, txt)\n",
        "            submit = submit.append({'file_name':file_name, 'class_id':class_id, 'confidence':confidence, 'point1_x':point1_x, 'point1_y':point1_y, 'point2_x':point2_x, 'point2_y':point2_y, 'point3_x':point3_x, 'point3_y':point3_y, 'point4_x':point4_x, 'point4_y':point4_y}, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piWsLFiFC2qS",
        "outputId": "f4a504aa-723e-49bc-a34a-516584b7ff48"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3395/3395 [03:17<00:00, 17.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv('/content/drive/MyDrive/resumefreeze.csv', index=False)"
      ],
      "metadata": {
        "id": "_ZUl-BI4C6xQ"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}